{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# pip install pandas\n",
    "# pip install geopandas"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb88815d5ca3ce46",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "This block imports the required Python libraries:\n",
    "\n",
    "pandas for handling tabular data (such as time series).\n",
    "geopandas for working with geospatial data (GeoPackage format).\n",
    "sqlite3 for connecting and interacting with an SQLite database.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ced4d77596ac1dd5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd  # Pandas is used for handling tabular data efficiently\n",
    "import geopandas as gpd  # Geopandas is used for handling geospatial data\n",
    "import sqlite3  # SQLite3 is used to connect and interact with an SQLite database"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-28T21:24:33.059508Z",
     "start_time": "2025-11-28T21:24:32.627658Z"
    }
   },
   "id": "initial_id",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "This block loads three geospatial layers from a GeoPackage (.gpkg) file using geopandas:\n",
    "\n",
    "POD_points: Contains the locations of Points of Diversion (POD), where water is withdrawn.\n",
    "event: Represents gage stations or hydrological monitoring points.\n",
    "ResOps_points: Includes information about reservoirs and their operations.\n",
    "Each layer is stored as a GeoDataFrame, allowing spatial analysis and attribute queries."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5f1818e7e7a7181a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Read geospatial layers from a GeoPackage file\n",
    "pod_layer = gpd.read_file('data/enhanced_reference_14.gpkg', layer='DIVERSION_POINTS')  \n",
    "# POD (Point of Diversion) layer contains locations where water is diverted\n",
    "\n",
    "gage_layer = gpd.read_file('data/enhanced_reference_14.gpkg', layer='event')  \n",
    "# Event layer contains gage locations or monitoring points\n",
    "\n",
    "res_layer = gpd.read_file('data/enhanced_reference_14.gpkg', layer='RESERVOIR_POINTS')  \n",
    "# Reservoir operations layer contains details about reservoirs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-28T21:24:34.890365Z",
     "start_time": "2025-11-28T21:24:34.784535Z"
    }
   },
   "id": "35c734f95392c613",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Config\n",
    "\n",
    "Start and end date for the simulation functionality "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a81bf64c7eb5572"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# HUC4 must match what you used when building the relational DB\n",
    "huc4_code = \"14\"\n",
    "\n",
    "# Path to the relational database\n",
    "db_path = f\"data/relational_db_{huc4_code}.db\"\n",
    "\n",
    "# Simulation window for reservoir operations (change as needed)\n",
    "start_date = \"10/1/2003\"\n",
    "end_date   = \"10/1/2013\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-28T21:24:36.633760Z",
     "start_time": "2025-11-28T21:24:36.631145Z"
    }
   },
   "id": "e37f29254f706d75",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "This block establishes a connection to an SQLite database to query key identifiers. First, it retrieves the POI_TypeID for \"Reservoir\" from the POI_Type table and the VariableID for \"Demand\" from the Variables table, both of which are crucial for querying related records.\n",
    "\n",
    "Next, the script iterates through each reservoir point in the res_layer, extracting its Source_comid (hydrofabric segment ID) and using it to look up the corresponding POIID in the POI table. Once the POIID is found, it queries the POI_Values table to retrieve the historical reservoir operation data (Inflows (CMS), Outflows (CMS) Storage amount (MCM)), which is then converted into a pandas.DataFrame for easy processing. Next, script retrieves data such as the POI_NativeID (a unique identifier) and the POI_Flow_ComID (hydrofabric segment ID) from the POI table.\n",
    "\n",
    "In each iteration, the script structures key variables for each point for integration into a water management model. These include the Reservoir’s unique ID, hydrofabric segment, and historical reservoir operation records. \n",
    "\n",
    "### <span style=\"color:red\">There is a specified block in the code that can be used to implement MODEL parametrizing code.</span> \n",
    "\n",
    "Use the specified variables in each iteration to inject data to the model with model specific functions. \n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "457dc7b675587475"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reservoir 0: POI_NATIVE_ID=WY01387, segment_comid=18303140\n",
      "  LocalDateTime  INFLOW  OUTFLOW  STORAGE\n",
      "0    2003-10-01   1.143    0.786    4.470\n",
      "1    2003-10-02   1.147    0.804    4.500\n",
      "2    2003-10-03   1.145    0.945    4.517\n",
      "3    2003-10-04   1.134    0.848    4.542\n",
      "4    2003-10-05   1.141    0.870    4.565\n",
      "Reservoir 1: POI_NATIVE_ID=WY01388, segment_comid=18303156\n",
      "  LocalDateTime  INFLOW  OUTFLOW  STORAGE\n",
      "0    2003-10-01     NaN      NaN      NaN\n",
      "1    2003-10-02     NaN      NaN      NaN\n",
      "2    2003-10-03     NaN      NaN      NaN\n",
      "3    2003-10-04     NaN      NaN      NaN\n",
      "4    2003-10-05     NaN      NaN      NaN\n",
      "Reservoir 2: POI_NATIVE_ID=WY01389, segment_comid=18355239\n",
      "  LocalDateTime  INFLOW  OUTFLOW  STORAGE\n",
      "0    2003-10-01  10.374   21.785  316.579\n",
      "1    2003-10-02  13.534   21.915  315.799\n",
      "2    2003-10-03  12.500   21.891  314.933\n",
      "3    2003-10-04  12.534   21.936  314.067\n",
      "4    2003-10-05  12.609   21.993  313.204\n",
      "Reservoir 3: POI_NATIVE_ID=WY01390, segment_comid=3197116\n",
      "  LocalDateTime  INFLOW  OUTFLOW  STORAGE\n",
      "0    2003-10-01   0.714    1.556    9.365\n",
      "1    2003-10-02   1.313    1.556    9.344\n",
      "2    2003-10-03   1.313    1.556    9.323\n",
      "3    2003-10-04   1.313    1.556    9.302\n",
      "4    2003-10-05   1.313    1.556    9.281\n",
      "Reservoir 4: POI_NATIVE_ID=UT10156, segment_comid=24712536\n",
      "  LocalDateTime  INFLOW  OUTFLOW  STORAGE\n",
      "0    2003-10-01   0.457    2.827    5.726\n",
      "1    2003-10-02   0.457    0.514    5.721\n",
      "2    2003-10-03   0.057    0.514    5.681\n",
      "3    2003-10-04   0.128    0.514    5.648\n",
      "4    2003-10-05   0.186    0.514    5.620\n",
      "Reservoir 5: POI_NATIVE_ID=UT10121, segment_comid=10040912\n",
      "  LocalDateTime  INFLOW  OUTFLOW   STORAGE\n",
      "0    2003-10-01  22.659   23.927  3249.878\n",
      "1    2003-10-02  22.475   23.613  3249.488\n",
      "2    2003-10-03  17.628   23.727  3248.690\n",
      "3    2003-10-04  22.244   23.713  3248.281\n",
      "4    2003-10-05  22.379   23.641  3247.892\n",
      "Reservoir 6: POI_NATIVE_ID=UT82901, segment_comid=1393725\n",
      "  LocalDateTime  INFLOW  OUTFLOW  STORAGE\n",
      "0    2003-10-01   0.300    1.156   15.378\n",
      "1    2003-10-02   0.343    1.156   15.307\n",
      "2    2003-10-03   0.214    1.071   15.233\n",
      "3    2003-10-04   0.129    0.985   15.159\n",
      "4    2003-10-05   0.514    0.985   15.119\n",
      "Reservoir 7: POI_NATIVE_ID=UT00608, segment_comid=11977035\n",
      "  LocalDateTime  INFLOW  OUTFLOW  STORAGE\n",
      "0    2003-10-01   0.957    0.143    1.888\n",
      "1    2003-10-02   1.099    0.200    1.892\n",
      "2    2003-10-03   1.099    0.229    1.896\n",
      "3    2003-10-04   1.071    0.229    1.897\n",
      "4    2003-10-05   0.985    0.200    1.893\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 81\u001B[0m\n\u001B[1;32m     78\u001B[0m timeseries_dict \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m     80\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m var_name, var_id \u001B[38;5;129;01min\u001B[39;00m variable_ids\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m---> 81\u001B[0m     \u001B[43mcursor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\"\"\u001B[39;49m\n\u001B[1;32m     82\u001B[0m \u001B[38;5;124;43m        SELECT LOCAL_DATE_TIME, DATA_VALUE\u001B[39;49m\n\u001B[1;32m     83\u001B[0m \u001B[38;5;124;43m        FROM POI_VALUES\u001B[39;49m\n\u001B[1;32m     84\u001B[0m \u001B[38;5;124;43m        WHERE POI_ID = ? AND VARIABLE_ID = ?\u001B[39;49m\n\u001B[1;32m     85\u001B[0m \u001B[38;5;124;43m        ORDER BY LOCAL_DATE_TIME\u001B[39;49m\n\u001B[1;32m     86\u001B[0m \u001B[38;5;124;43m    \u001B[39;49m\u001B[38;5;124;43m\"\"\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mpoiid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvar_id\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     87\u001B[0m     records \u001B[38;5;241m=\u001B[39m cursor\u001B[38;5;241m.\u001B[39mfetchall()\n\u001B[1;32m     89\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m records:\n\u001B[1;32m     90\u001B[0m         \u001B[38;5;66;03m# No time series for this variable / reservoir\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Connect to the relational DB defined in the previous cell\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1. Look up the POI_TYPE_ID for reservoirs\n",
    "# ------------------------------------------------------------------\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT POI_TYPE_ID\n",
    "    FROM POI_TYPE\n",
    "    WHERE POI_TYPE_NAME = 'RESERVOIR'\n",
    "\"\"\")\n",
    "poi_type_result = cursor.fetchone()\n",
    "\n",
    "if poi_type_result:\n",
    "    reservoir_poi_type_id = poi_type_result[0]\n",
    "else:\n",
    "    conn.close()\n",
    "    raise RuntimeError(\"No POI_TYPE_ID found for 'RESERVOIR' in the POI_TYPE table.\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2. Look up VARIABLE_IDs for reservoir variables\n",
    "#    (change names if your VARIABLES table uses different labels)\n",
    "# ------------------------------------------------------------------\n",
    "variable_names = [\"INFLOW\", \"OUTFLOW\", \"STORAGE\"]\n",
    "variable_ids = {}\n",
    "\n",
    "for var_name in variable_names:\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT VARIABLE_ID\n",
    "        FROM VARIABLES\n",
    "        WHERE VARIABLE_NAME = ?\n",
    "    \"\"\", (var_name,))\n",
    "    result = cursor.fetchone()\n",
    "    if result:\n",
    "        variable_ids[var_name] = result[0]\n",
    "    else:\n",
    "        print(f\"WARNING: No VARIABLE_ID found for '{var_name}' in VARIABLES\")\n",
    "\n",
    "if not variable_ids:\n",
    "    conn.close()\n",
    "    raise RuntimeError(\"No reservoir VARIABLE_IDs were found. Check the VARIABLES table.\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3. Loop over reservoir points from the RESERVOIR_POINTS layer\n",
    "# ------------------------------------------------------------------\n",
    "for idx, row in res_layer.iterrows():\n",
    "    # Hydrofabric COMID associated with this reservoir\n",
    "    # NOTE: change 'Source_comid' to match your actual column name\n",
    "    source_comid = row[\"SOURCE_COMID\"]\n",
    "\n",
    "    # Reservoir attributes from the geospatial layer\n",
    "    reservoir_name     = row[\"DAM_NAME\"]     # Designated reservoir name\n",
    "    reservoir_capacity = row[\"CAP_MCM\"]      # Max storage (million m³)\n",
    "    reservoir_height   = row[\"DAM_HGT_M\"]    # Dam height (m)\n",
    "    reservoir_main_use = row[\"MAIN_USE\"]     # Main purpose\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 3a. Look up POI_ID for this reservoir in POI table\n",
    "    # ------------------------------------------------------------------\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT POI_ID\n",
    "        FROM POI\n",
    "        WHERE POI_FLOW_COMID = ? AND POI_TYPE_ID = ?\n",
    "    \"\"\", (source_comid, reservoir_poi_type_id))\n",
    "    poiid_result = cursor.fetchone()\n",
    "\n",
    "    if not poiid_result:\n",
    "        # No matching POI row for this reservoir – skip\n",
    "        print(f\"No POI row found for reservoir COMID {source_comid}\")\n",
    "        continue\n",
    "\n",
    "    poiid = poiid_result[0]\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 3b. Get reservoir time-series (INFLOW, OUTFLOW, STORAGE) from POI_VALUES\n",
    "    # ------------------------------------------------------------------\n",
    "    timeseries_dict = {}\n",
    "\n",
    "    for var_name, var_id in variable_ids.items():\n",
    "        cursor.execute(\"\"\"\n",
    "            SELECT LOCAL_DATE_TIME, DATA_VALUE\n",
    "            FROM POI_VALUES\n",
    "            WHERE POI_ID = ? AND VARIABLE_ID = ?\n",
    "            ORDER BY LOCAL_DATE_TIME\n",
    "        \"\"\", (poiid, var_id))\n",
    "        records = cursor.fetchall()\n",
    "\n",
    "        if not records:\n",
    "            # No time series for this variable / reservoir\n",
    "            continue\n",
    "\n",
    "        df = pd.DataFrame(records, columns=[\"LocalDateTime\", var_name])\n",
    "        df[\"LocalDateTime\"] = pd.to_datetime(df[\"LocalDateTime\"])\n",
    "\n",
    "        # Apply simulation window\n",
    "        mask = (\n",
    "            (df[\"LocalDateTime\"] >= pd.to_datetime(start_date)) &\n",
    "            (df[\"LocalDateTime\"] <= pd.to_datetime(end_date))\n",
    "        )\n",
    "        df = df.loc[mask]\n",
    "\n",
    "        if df.empty:\n",
    "            continue\n",
    "\n",
    "        df.set_index(\"LocalDateTime\", inplace=True)\n",
    "        timeseries_dict[var_name] = df\n",
    "\n",
    "    if not timeseries_dict:\n",
    "        print(f\"No reservoir time-series found in window for COMID {source_comid}\")\n",
    "        continue\n",
    "\n",
    "    # Combine all variable DataFrames on datetime index\n",
    "    timeseries = pd.concat(timeseries_dict.values(), axis=1, join=\"outer\").reset_index()\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 3c. Get the reservoir's native ID and segment COMID from POI\n",
    "    # ------------------------------------------------------------------\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT POI_NATIVE_ID, POI_FLOW_COMID\n",
    "        FROM POI\n",
    "        WHERE POI_ID = ?\n",
    "    \"\"\", (poiid,))\n",
    "    poi_record = cursor.fetchone()\n",
    "\n",
    "    if not poi_record:\n",
    "        print(f\"No POI_NATIVE_ID/POI_FLOW_COMID found for POI_ID {poiid}\")\n",
    "        continue\n",
    "\n",
    "    poi_native_id, segment_comid = poi_record\n",
    "\n",
    "    # Optional: small sanity print\n",
    "    print(f\"Reservoir {idx}: POI_NATIVE_ID={poi_native_id}, segment_comid={segment_comid}\")\n",
    "    print(timeseries.head())\n",
    "\n",
    "    ##########################################################################\n",
    "    # MODEL HOOK BLOCK – use these variables for your WMM / hydrologic model\n",
    "    #\n",
    "    # 1. `POI_ID`            – Native ID of the reservoir point (POI)\n",
    "    # 2. `reservoir_name`    – Reservoir designated name\n",
    "    # 3. `reservoir_capacity`– Max storage capacity (million cubic meters)\n",
    "    # 4. `reservoir_height`  – Dam height (meters)\n",
    "    # 5. `reservoir_main_use`– Main purpose (Irrigation, Hydroelectricity, etc.)\n",
    "    # 6. `segment_comid`     – Hydrofabric segment ID where the reservoir is connected\n",
    "    # 7. `timeseries`        – Pandas DataFrame with columns:\n",
    "    #                            LocalDateTime, INFLOW, OUTFLOW, STORAGE\n",
    "    #\n",
    "    # -> Here is where you call your model-specific constructor / API:\n",
    "    #  \n",
    "    #        reservoir_id       = poi_native_id,\n",
    "    #        name               = reservoir_name,\n",
    "    #        segment_comid      = segment_comid,\n",
    "    #        capacity_mcm       = reservoir_capacity,\n",
    "    #        dam_height_m       = reservoir_height,\n",
    "    #        main_use           = reservoir_main_use,\n",
    "    #        ts_df              = timeseries,\n",
    "    #   \n",
    "    ##########################################################################\n",
    "\n",
    "# Close DB when finished\n",
    "conn.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-28T21:25:20.967187Z",
     "start_time": "2025-11-28T21:24:54.741807Z"
    }
   },
   "id": "d14c96a03253d09d",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "This block generates a model-ready summary table of all reservoirs in the HUC4 region by joining attributes from the geospatial reservoir layer (RESERVOIR_POINTS) with the corresponding reservoir entries stored in the relational database. For each reservoir, we extract its persistent POI identifier, core physical characteristics, and the Hydrofabric segment COMID where it connects to the flow network.\n",
    "\n",
    "The resulting table provides a compact representation of the key properties required for water-management modeling and can be directly used in workflow automation or WMM construction. Each row represents a single reservoir and includes:\n",
    "\n",
    "1. POI_ID – The persistent native POI identifier assigned during database ingestion.\n",
    "\n",
    "2. reservoir_name – Designated name of the reservoir or dam.\n",
    "\n",
    "3. reservoir_capacity – Maximum storage capacity (in million cubic meters).\n",
    "\n",
    "4. reservoir_height – Physical dam height (in meters).\n",
    "\n",
    "5. reservoir_main_use – Primary purpose of the reservoir (e.g., irrigation, hydropower, water supply, flood control, recreation).\n",
    "\n",
    "6. segment_comid – The Hydrofabric segment COMID where the reservoir is connected.\n",
    "\n",
    "Table provides a clean, standardized input that aligns with the diversion summary format and supports consistent integration with water-management models."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96a848eff517d9ee"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported reservoir summary table to: data/reservoirs_table_14.csv\n",
      "    POI_ID        reservoir_name  reservoir_capacity  reservoir_height  \\\n",
      "0  WY01387        Big Sandy Dike                67.1                 6   \n",
      "1  WY01388           Eden Dike 1                16.2                 9   \n",
      "2  WY01389            Fontenelle               185.6                42   \n",
      "3  WY01390           Meeks Cabin                36.4                56   \n",
      "4  UT10156  Bor Stateline Summit                17.3                39   \n",
      "\n",
      "  reservoir_main_use  segment_comid  \n",
      "0         Irrigation       18303140  \n",
      "1         Irrigation       18303156  \n",
      "2   Hydroelectricity       18355239  \n",
      "3         Irrigation        3197116  \n",
      "4         Irrigation       24712536  \n"
     ]
    }
   ],
   "source": [
    "# (Re)open a connection if needed\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# 1. Get POI_TYPE_ID for reservoirs\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT POI_TYPE_ID\n",
    "    FROM POI_TYPE\n",
    "    WHERE POI_TYPE_NAME = 'RESERVOIR'\n",
    "\"\"\")\n",
    "result = cursor.fetchone()\n",
    "if result:\n",
    "    reservoir_type_id = result[0]\n",
    "else:\n",
    "    raise RuntimeError(\"No POI_TYPE entry for 'RESERVOIR' found in POI_TYPE table.\")\n",
    "\n",
    "# 2. Build a summary table by joining RESERVOIR_POINTS to POI via COMID\n",
    "rows = []\n",
    "\n",
    "for idx, row in res_layer.iterrows():\n",
    "    source_comid        = row[\"SOURCE_COMID\"]\n",
    "    reservoir_name      = row[\"DAM_NAME\"]\n",
    "    reservoir_capacity  = row[\"CAP_MCM\"]\n",
    "    reservoir_height    = row[\"DAM_HGT_M\"]\n",
    "    reservoir_main_use  = row[\"MAIN_USE\"]\n",
    "\n",
    "    # Find corresponding POI record for this reservoir\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT POI_NATIVE_ID, POI_FLOW_COMID\n",
    "        FROM POI\n",
    "        WHERE POI_FLOW_COMID = ?\n",
    "          AND POI_TYPE_ID = ?\n",
    "    \"\"\", (source_comid, reservoir_type_id))\n",
    "    poi_record = cursor.fetchone()\n",
    "\n",
    "    if poi_record is None:\n",
    "        # If there is no matching POI, skip (or log)\n",
    "        print(f\"No POI found for reservoir COMID {source_comid}\")\n",
    "        continue\n",
    "\n",
    "    poi_native_id, segment_comid = poi_record\n",
    "\n",
    "    rows.append({\n",
    "        # 1. `POI_ID` - Native ID of the reservoir point (POI)\n",
    "        \"POI_ID\": poi_native_id,\n",
    "\n",
    "        # 2. 'reservoir_name' - Reservoir designated name\n",
    "        \"reservoir_name\": reservoir_name,\n",
    "\n",
    "        # 3. 'reservoir_capacity' - Max storage capacity (million cubic meters)\n",
    "        \"reservoir_capacity\": reservoir_capacity,\n",
    "\n",
    "        # 4. 'reservoir_height' - Dam height (meters)\n",
    "        \"reservoir_height\": reservoir_height,\n",
    "\n",
    "        # 5. 'reservoir_main_use' - Main purpose\n",
    "        \"reservoir_main_use\": reservoir_main_use,\n",
    "\n",
    "        # 6. `segment_comid` - Hydrofabric segment ID where reservoir is connected\n",
    "        \"segment_comid\": segment_comid,\n",
    "    })\n",
    "\n",
    "reservoirs_df = pd.DataFrame(rows)\n",
    "\n",
    "# 3. Export CSV\n",
    "output_path = f\"data/reservoirs_table_{huc4_code}.csv\"\n",
    "reservoirs_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Exported reservoir summary table to: {output_path}\")\n",
    "print(reservoirs_df.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-28T21:26:37.111339Z",
     "start_time": "2025-11-28T21:26:37.080661Z"
    }
   },
   "id": "80ae35b351ecc0dd",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c30b760cef3ffca9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
