{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# pip install pandas\n",
    "# pip install geopandas"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb88815d5ca3ce46"
  },
  {
   "cell_type": "markdown",
   "source": [
    "This block imports the required Python libraries:\n",
    "\n",
    "pandas for handling tabular data (such as time series).\n",
    "geopandas for working with geospatial data (GeoPackage format).\n",
    "sqlite3 for connecting and interacting with an SQLite database.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ced4d77596ac1dd5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd  # Pandas is used for handling tabular data efficiently\n",
    "import geopandas as gpd  # Geopandas is used for handling geospatial data\n",
    "import sqlite3  # SQLite3 is used to connect and interact with an SQLite database"
   ],
   "metadata": {
    "collapsed": true
   },
   "id": "initial_id",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "This block loads three geospatial layers from a GeoPackage (.gpkg) file using geopandas:\n",
    "\n",
    "POD_points: Contains the locations of Points of Diversion (POD), where water is withdrawn.\n",
    "event: Represents gage stations or hydrological monitoring points.\n",
    "ResOps_points: Includes information about reservoirs and their operations.\n",
    "Each layer is stored as a GeoDataFrame, allowing spatial analysis and attribute queries."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5f1818e7e7a7181a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Read geospatial layers from a GeoPackage file\n",
    "pod_layer = gpd.read_file('data/enhanced_reference_14.gpkg', layer='DIVERSION_POINTS')  \n",
    "# POD (Point of Diversion) layer contains locations where water is diverted\n",
    "\n",
    "gage_layer = gpd.read_file('data/enhanced_reference_14.gpkg', layer='event')  \n",
    "# Event layer contains gage locations or monitoring points\n",
    "\n",
    "res_layer = gpd.read_file('data/enhanced_reference_14.gpkg', layer='RESERVOIR_POINTS')  \n",
    "# Reservoir operations layer contains details about reservoirs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35c734f95392c613",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Start and end date for the data querries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a81bf64c7eb5572"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "start_date = '10/1/2003'  #specify start date for time series data\n",
    "end_date = '10/1/2013'  #specify end date for time series data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e37f29254f706d75",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4ef544a7f40509af"
  },
  {
   "cell_type": "markdown",
   "source": [
    "This block establishes a connection to an SQLite database to query key identifiers. First, it retrieves the POI_TypeID for \"POD\" from the POI_Type table and the VariableID for \"Demand\" from the Variables table, both of which are crucial for querying related records.\n",
    "\n",
    "Next, the script iterates through each diversion point in the pod_layer, extracting its Source_comid (hydrofabric segment ID) and using it to look up the corresponding POIID in the POI table. Once the POIID is found, it queries the POI_Values table to retrieve the historical demand time series, which is then converted into a pandas.DataFrame for easy processing. Additionally, it fetches water rights information, including the allocation date and the legally permitted water withdrawal rate (CFS) from the POD_WaterRights table. Next, script retrieves data such as the POI_NativeID (a unique identifier) and the POI_Flow_ComID (hydrofabric segment ID) from the POI table.\n",
    "\n",
    "In each iteration, the script structures key variables for each point for integration into a water management model. These include the diversion point’s unique ID, hydrofabric segment, water rights information, and historical demand records. \n",
    "\n",
    "### <span style=\"color:red\">There is a specified block in the code that can be used to implement MODEL parametrizing code.</span> \n",
    "\n",
    "Use the specified variables in each iteration to inject data to the model with model specific functions. \n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "457dc7b675587475"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# This HUC4 must match what you used when building the DB\n",
    "huc4_code = '14'\n",
    "db_path = f'data/relational_db_{huc4_code}.db'\n",
    "\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1. Look up the POI_TYPE_ID for POD (Points of Diversion)\n",
    "# ------------------------------------------------------------------\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT POI_TYPE_ID\n",
    "    FROM POI_TYPE\n",
    "    WHERE POI_TYPE_NAME = 'POD'\n",
    "\"\"\")\n",
    "poi_type_result = cursor.fetchone()\n",
    "\n",
    "if poi_type_result:\n",
    "    diversion_poi_type_id = poi_type_result[0]\n",
    "else:\n",
    "    raise RuntimeError(\"No POI_TYPE_ID found for 'POD' in the POI_TYPE table.\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2. Look up the VARIABLE_ID for the demand / diversion variable\n",
    "#    (change 'Demand' if you use a different VARIABLE_NAME)\n",
    "# ------------------------------------------------------------------\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT VARIABLE_ID\n",
    "    FROM VARIABLES\n",
    "    WHERE VARIABLE_NAME = 'DEMAND'\n",
    "\"\"\")\n",
    "variable_id_result = cursor.fetchone()\n",
    "\n",
    "if variable_id_result:\n",
    "    demand_variable_id = variable_id_result[0]\n",
    "else:\n",
    "    raise RuntimeError(\"No VARIABLE_ID found for 'Demand' in the VARIABLES table.\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3. Loop over diversion points (PODs) from the GeoPackage layer\n",
    "# ------------------------------------------------------------------\n",
    "for idx, row in pod_layer.iterrows():\n",
    "    # Hydrofabric COMID associated with this POD (from the POD_points layer)\n",
    "    source_comid = row['SOURCE_COMID']\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 3a. Look up the POI_ID for this COMID and POD POI_TYPE\n",
    "    # ------------------------------------------------------------------\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT POI_ID\n",
    "        FROM POI\n",
    "        WHERE POI_FLOW_COMID = ? AND POI_TYPE_ID = ?\n",
    "    \"\"\", (source_comid, diversion_poi_type_id))\n",
    "    poiid_result = cursor.fetchone()\n",
    "\n",
    "    if not poiid_result:\n",
    "        # No matching POI row for this POD – skip it\n",
    "        continue\n",
    "\n",
    "    poiid = poiid_result[0]  # Primary key in the POI table for this diversion\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 3b. Get time-series demand values from POI_VALUES\n",
    "    # ------------------------------------------------------------------\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT LOCAL_DATE_TIME, DATA_VALUE\n",
    "        FROM POI_VALUES\n",
    "        WHERE POI_ID = ? AND VARIABLE_ID = ?\n",
    "        ORDER BY LOCAL_DATE_TIME\n",
    "    \"\"\", (poiid, demand_variable_id))\n",
    "    ts_records = cursor.fetchall()\n",
    "\n",
    "    demand_timeseries = pd.DataFrame(\n",
    "        ts_records,\n",
    "        columns=['LOCAL_DATE_TIME', 'DiversionValue']\n",
    "    )\n",
    "\n",
    "    # Convert to datetime and apply the simulation start/end window\n",
    "    if not demand_timeseries.empty:\n",
    "        demand_timeseries['LOCAL_DATE_TIME'] = pd.to_datetime(\n",
    "            demand_timeseries['LOCAL_DATE_TIME'],\n",
    "            errors='coerce'\n",
    "        )\n",
    "\n",
    "        mask = (\n",
    "            (demand_timeseries['LOCAL_DATE_TIME'] >= pd.to_datetime(start_date)) &\n",
    "            (demand_timeseries['LOCAL_DATE_TIME'] <= pd.to_datetime(end_date))\n",
    "        )\n",
    "        demand_timeseries = demand_timeseries.loc[mask].reset_index(drop=True)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 3c. Get water-right attributes from POD_WATER_RIGHTS\n",
    "    # ------------------------------------------------------------------\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT WATER_RIGHT_ID, ALLOCATION_DATE, ALLOCATION_CFS\n",
    "        FROM POD_WATER_RIGHTS\n",
    "        WHERE POI_ID = ?\n",
    "    \"\"\", (poiid,))\n",
    "    waterrights_result = cursor.fetchall()\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 3d. Get the diversion's native ID and flow segment COMID from POI\n",
    "    # ------------------------------------------------------------------\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT POI_NATIVE_ID, POI_FLOW_COMID\n",
    "        FROM POI\n",
    "        WHERE POI_ID = ?\n",
    "    \"\"\", (poiid,))\n",
    "    diversion_record = cursor.fetchone()\n",
    "\n",
    "    if diversion_record:\n",
    "        diversion_ID = diversion_record[0]   # Native ID of the diversion (e.g., WDID)\n",
    "        segment_comid = diversion_record[1]  # Hydrofabric segment COMID\n",
    "    else:\n",
    "        diversion_ID = None\n",
    "        segment_comid = None\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 3e. (Optional) Print a quick summary for inspection\n",
    "    # ------------------------------------------------------------------\n",
    "    print()\n",
    "    print(f\"{diversion_ID} (COMID {segment_comid}):\")\n",
    "\n",
    "    for wr in waterrights_result:\n",
    "        water_right_id = wr[0]\n",
    "        allocation_date = wr[1]\n",
    "        allocation_value_cfs = wr[2]\n",
    "        print(f\"  WR {water_right_id}: {allocation_date}, {allocation_value_cfs} cfs\")\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 3f. PLACEHOLDER: hook this diversion into your WMM / hydrologic model\n",
    "    # ------------------------------------------------------------------\n",
    "    # At this point in each loop iteration you have:\n",
    "    #   1. diversion_ID        – ID of the diversion point (POI_NATIVE_ID)\n",
    "    #   2. segment_comid       – Hydrofabric segment ID where the diversion occurs\n",
    "    #   3. waterrights_result  – list of (WATER_RIGHT_ID, ALLOCATION_DATE, ALLOCATION_CFS)\n",
    "    #   4. demand_timeseries   – DataFrame with (LOCAL_DATE_TIME, DiversionValue)\n",
    "    #                             within the [start_date, end_date] simulation window\n",
    "    #\n",
    "    # Use these variables to parameterize your model-specific diversion object\n",
    "    # (create nodes/links, demand patterns, allocation rules, etc.).\n",
    "\n",
    "# Close the database connection when finished\n",
    "conn.close()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d14c96a03253d09d",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "This block extracts a summary of all diversion points (PODs) stored in the SQLite database and exports them as a standalone CSV file for reference or downstream analysis. Diversions are stored in the POI table, and each diversion is identified by the POI_TYPE entry with the name \"POD\".\n",
    "\n",
    "The code performs the following steps:\n",
    "\n",
    "1. Connects to the SQLite database generated during the data-building workflow.\n",
    "\n",
    "2. Retrieves the POI_TYPE_ID for diversions so only POD-type points are selected.\n",
    "\n",
    "3. Queries the POI table to extract key attributes for each diversion, including:\n",
    "\n",
    "* diversion_id — the native identifier for the diversion (e.g., WDID).\n",
    "\n",
    "* lat, long — geographic coordinates stored in the database.\n",
    "\n",
    "* comid — the Hydrofabric flowline COMID where the diversion withdraws water.\n",
    "\n",
    "4. Creates a Pandas DataFrame with these fields.\n",
    "\n",
    "5.  Exports the table as a CSV file to the data/publish_output/ directory using a name that includes the HUC4 code (e.g., diversions_table_14.csv).\n",
    "\n",
    "Table provides a convenient way to inspect all diversion points, validate their spatial attributes, or integrate them into external workflows such as visualization, geoprocessing, or companion water-management models."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f31b2612d0fc6353"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# 1. Find POI_TYPE_ID for POD (Diversions)\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT POI_TYPE_ID\n",
    "    FROM POI_TYPE\n",
    "    WHERE POI_TYPE_NAME = 'POD'\n",
    "\"\"\")\n",
    "result = cursor.fetchone()\n",
    "if result:\n",
    "    diversion_type_id = result[0]\n",
    "else:\n",
    "    raise RuntimeError(\"No POI_TYPE entry for 'POD' found.\")\n",
    "\n",
    "# 2. Pull diversion records and cumulative allocation (cfs)\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT \n",
    "        p.POI_NATIVE_ID      AS diversion_id,\n",
    "        p.POI_LAT            AS lat,\n",
    "        p.POI_LON            AS long,\n",
    "        p.POI_FLOW_COMID     AS comid,\n",
    "        COALESCE(SUM(w.ALLOCATION_CFS), 0.0) AS allocation_cfs\n",
    "    FROM POI p\n",
    "    LEFT JOIN POD_WATER_RIGHTS w\n",
    "        ON p.POI_ID = w.POI_ID\n",
    "    WHERE p.POI_TYPE_ID = ?\n",
    "    GROUP BY \n",
    "        p.POI_ID,\n",
    "        p.POI_NATIVE_ID,\n",
    "        p.POI_LAT,\n",
    "        p.POI_LON,\n",
    "        p.POI_FLOW_COMID\n",
    "\"\"\"\n",
    "\n",
    "diversions_df = pd.read_sql_query(query, conn, params=(diversion_type_id,))\n",
    "\n",
    "# 3. Export CSV\n",
    "output_path = f'data/diversions_table_{huc4_code}.csv'\n",
    "diversions_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Exported diversion table to: {output_path}\")\n",
    "print(diversions_df.head())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "70b3678383e0e00a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4c9c9fbac1bed06a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
